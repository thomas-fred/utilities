#!/bin/bash

# 20250109
# F. Thomas
#
# Some OUCE cluster nodes are silently swallowing jobs
# It's useful to have a way to exclude these from a job request
#
# Submitted jobs may:
# A) Run immediately on a free node
# B) Be queued and then run successfully later on a currently busy node
# C) Be eaten by a bad node, vanishing from the queue and not producing any output
#
# This script lists the nodes involved in class B & C behaviour
# You may use the resulting list as part of an --exclude argument to SLURM, e.g.
# srun -p Short --exclude=$(exclude-list Short) bash -c "date && hostname"

usage() {
    echo "Run with partition as argument to determine nodes not currently available, e.g."
    echo "$(basename $0) Short"
}

PARTITION=$1
if [[ "$PARTITION" =~ ^(Short|Medium|Long|GPU)$ ]]; then
    :
else
    usage
    exit 1
fi

# use sinfo to query SLURM for the nodes it recognises as up
# this may not necessarily be all of 01..max
# N.B. an exclude request with a non-existent node will fail
ACTIVE_NODES=$(sinfo --json | jq --raw-output .nodes[].name)
ACTIVE_NODES_FILE=$(mktemp)
echo $ACTIVE_NODES > $ACTIVE_NODES_FILE

test_nodes() {
    # launch a small job on each node to see if it runs
    for NODE in $ACTIVE_NODES; do
        srun -p $PARTITION --nodelist=$NODE bash -c "hostname" &
    done

    sleep 2

    # cancel any jobs that are still pending (busy nodes)
    scancel --state=PENDING --user=$USER
}

# happy, free nodes that immediately ran our job
CLASS_A=$(test_nodes 2>&1 | grep ouce-)
CLASS_A_FILE=$(mktemp)
echo $CLASS_A > $CLASS_A_FILE

# find the difference between active and class A sets
# print to STDOUT
python -c "
with open('$CLASS_A_FILE', 'r') as fp:
    a = set(map(lambda s: s.rstrip(), fp.read().split(' ')))
with open('$ACTIVE_NODES_FILE', 'r') as fp:
    active = set(map(lambda s: s.rstrip(), fp.read().split(' ')))
print(','.join(sorted(active - a)))
"

# cleanup
rm $CLASS_A_FILE
rm $ACTIVE_NODES_FILE
